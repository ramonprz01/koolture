{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk, re\n",
    "# nltk.download('wordnet')\n",
    "import scipy as sp\n",
    "import math\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import csv\n",
    "from functools import partial\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_parquet('nameoffile', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_df = pd.read_pickle(\"Netflix_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employer</th>\n",
       "      <th>id</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Express</td>\n",
       "      <td>44001</td>\n",
       "      <td>Still not big enough in market place</td>\n",
       "      <td>Great brand , Good leadership , Clear business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eventum IT Solutions</td>\n",
       "      <td>44004</td>\n",
       "      <td>Nothing important on my point of view.</td>\n",
       "      <td>Learn new technologies, helpful people, good m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eventum IT Solutions</td>\n",
       "      <td>44004</td>\n",
       "      <td>Alot of friends working together which isn't v...</td>\n",
       "      <td>Very good opportunities to learn technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eventum IT Solutions</td>\n",
       "      <td>44004</td>\n",
       "      <td>Working hours are not good and need to add the...</td>\n",
       "      <td>You can learn technically a lot in this company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eventum IT Solutions</td>\n",
       "      <td>44004</td>\n",
       "      <td>No Real Cons at all</td>\n",
       "      <td>- Very friendly environment.\\r\\n- Highly exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               employer     id  \\\n",
       "0      American Express  44001   \n",
       "1  Eventum IT Solutions  44004   \n",
       "2  Eventum IT Solutions  44004   \n",
       "3  Eventum IT Solutions  44004   \n",
       "4  Eventum IT Solutions  44004   \n",
       "\n",
       "                                                pros  \\\n",
       "0               Still not big enough in market place   \n",
       "1             Nothing important on my point of view.   \n",
       "2  Alot of friends working together which isn't v...   \n",
       "3  Working hours are not good and need to add the...   \n",
       "4                                No Real Cons at all   \n",
       "\n",
       "                                                cons  \n",
       "0  Great brand , Good leadership , Clear business...  \n",
       "1  Learn new technologies, helpful people, good m...  \n",
       "2      Very good opportunities to learn technologies  \n",
       "3   You can learn technically a lot in this company.  \n",
       "4  - Very friendly environment.\\r\\n- Highly exper...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_gs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will remove the company names from their respective reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def comp_name_out(data, col_to_search, col_reviews, companies_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in a dataframe, the name of the column with all of \n",
    "    the companies, the name of the column with the reviews, and an iterable\n",
    "    with the companies names that are in the dataset. The latter could be a list,\n",
    "    set, Series, tuple, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    for company in companies_list:\n",
    "        condition = (data[col_to_search] == company)\n",
    "        data.loc[condition, col_reviews] = data.loc[condition, col_reviews].str.lower().str.strip(company.lower())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function helps with the preprocessing of the data. It runs after the lemmatizer, stemmer, snowball, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_doc(doc):\n",
    "    \"\"\"\n",
    "    This function normalizes your list of documents by taking only\n",
    "    words, numbers, and spaces in between them. It then filters out\n",
    "    stop words if you want to.\n",
    "    \"\"\"\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "#     filtered_tokens = [token for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the root of the word. You can get all three (lemma, stem, and snow) or use them separately with the partial functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_of_word(docs, root_word_method='lemma'):\n",
    "    porter_stemmer = nltk.stem.PorterStemmer()\n",
    "    snowball_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    \n",
    "    tokens = nltk.word_tokenize(docs)\n",
    "    \n",
    "    if root_word_method == 'lemma':\n",
    "        doc = ' '.join([lemma.lemmatize(w) for w in tokens])\n",
    "    elif root_word_method == 'stemm':\n",
    "        doc = ' '.join([porter_stemmer.stem(w) for w in tokens])\n",
    "    elif root_word_method == 'snowball':\n",
    "        doc = ' '.join([snowball_stemmer.stem(w) for w in tokens])\n",
    "        \n",
    "    return doc\n",
    "\n",
    "stemming = partial(root_of_word, root_word_method='stemm')\n",
    "snowball = partial(root_of_word, root_word_method='snowball')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsd(p, q, base=np.e): # JS distance between probability vectors, used to compute compH\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    m = (1 / 2 * (p + q))\n",
    "    return sp.stats.entropy(p, m, base) / 2 +  sp.stats.entropy(q, m, base) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conth(data): # function to measure content heterogeneity given a topic (prob) matrix\n",
    "    return (1 / ((sum(map(sum, np.square(data.values)))) / data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comph(data): \n",
    "    #Transform probMatrix_df into 2D array\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(len(data)): \n",
    "        jsd_list = []\n",
    "        for y in range(len(data)): \n",
    "            jsd_list.append(jsd(data[x], data[y]))\n",
    "        df[str(x)] = jsd_list\n",
    "\n",
    "    #Get df lower diagonal\n",
    "    mask = np.ones(df.shape, dtype='bool')\n",
    "    mask[np.triu_indices(len(df))] = False\n",
    "    df_lower_diagonal = df[(df>-1) & mask]\n",
    "    \n",
    "    distance_list = []\n",
    "    for k in range(len(df)): \n",
    "    #Transform each column of df_lower_diagonal into list\n",
    "        column_list = df_lower_diagonal[str(k)].values.tolist()\n",
    "        #Drop nan values from column_list - to retain only actual values from lower diagonal \n",
    "        column_lower_diagonal_list = [l for l in column_list if (math.isnan(l) == False)]\n",
    "        for d in column_lower_diagonal_list: \n",
    "            distance_list.append(d)\n",
    "            \n",
    "    return sum(distance_list) / float(len(distance_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the company names from the reviews, and extract the reviews into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['American Express', 'Eventum IT Solutions', 'Hays',\n",
       "       'Verizon\\xa0Connect'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = df['employer'].unique()\n",
    "companies[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 708 ms, total: 2min 4s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = comp_name_out(df, 'employer', 'pros', companies)\n",
    "data_pros = df['pros'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text preprocessing of the corpus takes place in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with cf.ProcessPoolExecutor() as e:\n",
    "    data_pros_cleaned = e.map(stemming, data_pros)\n",
    "    data_pros_cleaned = list(e.map(normalize_doc, data_pros_cleaned))\n",
    "\n",
    "df['pros_clean'] = data_pros_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total words in the dictionary of review words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalWords_vectorizer = CountVectorizer()\n",
    "TotalWords_tf = TotalWords_vectorizer.fit_transform(data_pros)\n",
    "totWords = len(TotalWords_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cleaned dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon                              561\n",
       "Oracle                              422\n",
       "Microsoft                           349\n",
       "Siemens                             343\n",
       "Dell Technologies                   338\n",
       "IBM                                 337\n",
       "EY                                  324\n",
       "PwC                                 300\n",
       "SAP                                 295\n",
       "Citi                                253\n",
       "Accenture                           250\n",
       "DXC Technology                      249\n",
       "Cisco Systems                       232\n",
       "Google                              221\n",
       "Deloitte                            215\n",
       "Ericsson-Worldwide                  211\n",
       "Nokia                               204\n",
       "Capgemini                           198\n",
       "Procter & Gamble                    191\n",
       "IQVIA                               191\n",
       "McKinsey & Company                  185\n",
       "Vodafone                            169\n",
       "Honeywell                           164\n",
       "Intel Corporation                   163\n",
       "Philips                             162\n",
       "Hewlett Packard Enterprise | HPE    155\n",
       "Hays                                155\n",
       "Orange                              153\n",
       "Nielsen                             151\n",
       "ABB                                 149\n",
       "Schneider Electric                  147\n",
       "Roche                               146\n",
       "Boston Consulting Group             146\n",
       "VMware                              133\n",
       "Salesforce                          132\n",
       "Continental                         132\n",
       "Altran Group                        128\n",
       "Johnson & Johnson                   125\n",
       "Thales                              125\n",
       "Marriott International              120\n",
       "Synopsys                            119\n",
       "J.P. Morgan                         117\n",
       "Luxoft                              117\n",
       "KPMG                                116\n",
       "Amdocs                              114\n",
       "Cognizant Technology Solutions      113\n",
       "Shell                               111\n",
       "NCR                                 111\n",
       "NTT                                 110\n",
       "Verizon                             107\n",
       "JLL                                 106\n",
       "Thermo Fisher Scientific            106\n",
       "Société Générale                    103\n",
       "HP Inc.                             103\n",
       "Mondelēz International              102\n",
       "Uber                                101\n",
       "UBS                                  99\n",
       "GE Healthcare                        97\n",
       "GlaxoSmithKline                      96\n",
       "AstraZeneca                          94\n",
       "Name: employer, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.employer.value_counts().head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amazon', 'Oracle', 'Microsoft', 'Siemens', 'Dell Technologies', 'IBM',\n",
       "       'EY', 'PwC', 'SAP', 'Citi', 'Accenture', 'DXC Technology',\n",
       "       'Cisco Systems', 'Google', 'Deloitte', 'Ericsson-Worldwide', 'Nokia',\n",
       "       'Capgemini', 'Procter & Gamble', 'IQVIA', 'McKinsey & Company',\n",
       "       'Vodafone', 'Honeywell', 'Intel Corporation', 'Philips',\n",
       "       'Hewlett Packard Enterprise | HPE', 'Hays', 'Orange', 'Nielsen', 'ABB',\n",
       "       'Schneider Electric', 'Roche', 'Boston Consulting Group', 'VMware',\n",
       "       'Salesforce', 'Continental', 'Altran Group', 'Johnson & Johnson',\n",
       "       'Thales', 'Marriott International', 'Synopsys', 'J.P. Morgan', 'Luxoft',\n",
       "       'KPMG', 'Amdocs', 'Cognizant Technology Solutions', 'Shell', 'NCR',\n",
       "       'NTT', 'Verizon', 'JLL', 'Thermo Fisher Scientific', 'Société Générale',\n",
       "       'HP Inc.', 'Mondelēz International', 'Uber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps_of_interest = df.employer.value_counts()\n",
    "comps_of_interest = (comps_of_interest[comps_of_interest > 100]).index\n",
    "comps_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employer</th>\n",
       "      <th>id</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>pros_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hays</td>\n",
       "      <td>44012</td>\n",
       "      <td>- sink or swim (but this is the nature of most...</td>\n",
       "      <td>- Clear career path.\\r\\n- Motivated management...</td>\n",
       "      <td>sink swim thi natur recruit firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hays</td>\n",
       "      <td>44012</td>\n",
       "      <td>- management does not listen to advice from no...</td>\n",
       "      <td>- Excellent view from the office\\r\\n- Friendly...</td>\n",
       "      <td>manag doe listen advic nonmanageri staff lack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hays</td>\n",
       "      <td>44012</td>\n",
       "      <td>it has a result-oriented nature</td>\n",
       "      <td>Great opportunity to learn the recruitment pro...</td>\n",
       "      <td>ha resultori natur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hays</td>\n",
       "      <td>44012</td>\n",
       "      <td>- high pressure culture instead of high perfor...</td>\n",
       "      <td>- Location\\r\\n- International transfer\\r\\n- Af...</td>\n",
       "      <td>high pressur cultur instead high perform work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hays</td>\n",
       "      <td>44012</td>\n",
       "      <td>those who are most successful at hays are indi...</td>\n",
       "      <td>Hays' culture is build on meritocracy. The Com...</td>\n",
       "      <td>success hay individu look onli meet expect exceed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employer     id                                               pros  \\\n",
       "6      Hays  44012  - sink or swim (but this is the nature of most...   \n",
       "7      Hays  44012  - management does not listen to advice from no...   \n",
       "8      Hays  44012                    it has a result-oriented nature   \n",
       "9      Hays  44012  - high pressure culture instead of high perfor...   \n",
       "10     Hays  44012  those who are most successful at hays are indi...   \n",
       "\n",
       "                                                 cons  \\\n",
       "6   - Clear career path.\\r\\n- Motivated management...   \n",
       "7   - Excellent view from the office\\r\\n- Friendly...   \n",
       "8   Great opportunity to learn the recruitment pro...   \n",
       "9   - Location\\r\\n- International transfer\\r\\n- Af...   \n",
       "10  Hays' culture is build on meritocracy. The Com...   \n",
       "\n",
       "                                           pros_clean  \n",
       "6                    sink swim thi natur recruit firm  \n",
       "7   manag doe listen advic nonmanageri staff lack ...  \n",
       "8                                  ha resultori natur  \n",
       "9   high pressur cultur instead high perform work ...  \n",
       "10  success hay individu look onli meet expect exceed  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond2 = df['employer'].isin(comps_of_interest)\n",
    "df.loc[cond2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10380, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interest = df[cond2].copy()\n",
    "df_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44012,  44217,  50043,     49,    299,  44921,  45078,  55507,\n",
       "        61101,  72119,  72338,  80275,  83451,  74278,  99683, 106752,\n",
       "        86243, 122908, 126224, 110150, 127512, 110590,  18125,  33433,\n",
       "       125242, 105872, 156170, 156784,  20989,  39478,  73626,  77815,\n",
       "        40902, 130784, 151854, 155333,  14069,   4757,  51658,  78820,\n",
       "        79094, 153812])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interest.loc[df_interest['employer'] == 'Hays', 'id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hays', 'Boston Consulting Group', 'Oracle', 'Philips'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = df_interest['employer'].unique()\n",
    "unique_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 336 ms, sys: 48.9 ms, total: 385 ms\n",
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizers_list = []\n",
    "for comp_id in unique_ids:\n",
    "    cond = (df_interest['employer'] == comp_id)\n",
    "    revs_clean = df_interest.loc[cond, 'pros_clean'].values\n",
    "    vect = CountVectorizer().fit_transform(revs_clean)\n",
    "    vectorizers_list.append((comp_id, vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hays',\n",
       "  <155x1290 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 2417 stored elements in Compressed Sparse Row format>),\n",
       " ('Boston Consulting Group',\n",
       "  <146x916 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 1750 stored elements in Compressed Sparse Row format>),\n",
       " ('Oracle',\n",
       "  <422x1631 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 4710 stored elements in Compressed Sparse Row format>),\n",
       " ('Philips',\n",
       "  <162x1015 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 1758 stored elements in Compressed Sparse Row format>)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizers_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_vectorizer = CountVectorizer(max_df = 0.90, min_df=0.01)\n",
    "# tf = tf_vectorizer.fit_transform(data_pros_cleaned)\n",
    "# tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of words in the final dictionary that can be found in the full corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39332742564867934"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percVoc = len(tf_feature_names) / totWords * 100\n",
    "percVoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parallelize the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_range = range(2, 300, 5)\n",
    "\n",
    "def get_models(topics, tf):\n",
    "    lda = LatentDirichletAllocation(n_components=topics, max_iter=200, learning_method='batch', learning_offset=10.,evaluate_every=2, random_state=1234)\n",
    "    lda_model = lda.fit(tf[1])\n",
    "    topicsOverWords = lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis]\n",
    "    return (tf[0], topics, comph(topicsOverWords), lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the models in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 32 s, total: 47.8 s\n",
      "Wall time: 1h 55min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_dictionary = {}\n",
    "for sparse_tup in vectorizers_list:\n",
    "    partial_func = partial(get_models, tf=sparse_tup)\n",
    "    with cf.ProcessPoolExecutor() as e:\n",
    "        output = list(e.map(partial_func, our_range))\n",
    "    output_dictionary[sparse_tup[0]] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.9 ms, sys: 38.6 ms, total: 104 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dfs_list = []\n",
    "for data in output_dictionary.keys():\n",
    "    temp_df = pd.DataFrame.from_dict(output_dictionary[data])\n",
    "    dfs_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hays</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280552</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hays</td>\n",
       "      <td>7</td>\n",
       "      <td>0.255732</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hays</td>\n",
       "      <td>12</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hays</td>\n",
       "      <td>17</td>\n",
       "      <td>0.289898</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hays</td>\n",
       "      <td>22</td>\n",
       "      <td>0.294427</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company  topics  coherence  \\\n",
       "0    Hays       2   0.280552   \n",
       "1    Hays       7   0.255732   \n",
       "2    Hays      12   0.276000   \n",
       "3    Hays      17   0.289898   \n",
       "4    Hays      22   0.294427   \n",
       "\n",
       "                                              models  \n",
       "0  LatentDirichletAllocation(evaluate_every=2, ma...  \n",
       "1  LatentDirichletAllocation(evaluate_every=2, ma...  \n",
       "2  LatentDirichletAllocation(evaluate_every=2, ma...  \n",
       "3  LatentDirichletAllocation(evaluate_every=2, ma...  \n",
       "4  LatentDirichletAllocation(evaluate_every=2, ma...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dfs = pd.concat(dfs_list)\n",
    "output_dfs.columns = ['company', 'topics', 'coherence', 'models']\n",
    "output_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['American Express', 'Eventum IT Solutions', 'Hays', ...,\n",
       "       'Elkem Silicones', 'Clarity Insights', \"Dr. Reddy's\"], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_topics_model = defaultdict(tuple)\n",
    "for company in unique_ids:\n",
    "    cond = output_dfs['company'] == company\n",
    "    filtered_data = output_dfs[cond]\n",
    "    the_topic = int(filtered_data.loc[filtered_data['coherence'].idxmax(), 'topics'])\n",
    "    the_model = filtered_data.loc[filtered_data['coherence'].idxmax(), 'models']\n",
    "    best_topics_model[company] = (the_topic, the_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(tuple,\n",
       "            {'Hays': (72,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=72,\n",
       "                                        random_state=1234)),\n",
       "             'Boston Consulting Group': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'Oracle': (137,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=137,\n",
       "                                        random_state=1234)),\n",
       "             'Philips': (87,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=87,\n",
       "                                        random_state=1234)),\n",
       "             'IBM': (92,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=92,\n",
       "                                        random_state=1234)),\n",
       "             'Amazon': (222,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=222,\n",
       "                                        random_state=1234)),\n",
       "             'Orange': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'DXC Technology': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Deloitte': (92,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=92,\n",
       "                                        random_state=1234)),\n",
       "             'Citi': (112,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=112,\n",
       "                                        random_state=1234)),\n",
       "             'Microsoft': (122,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=122,\n",
       "                                        random_state=1234)),\n",
       "             'Altran Group': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'NTT': (32,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=32,\n",
       "                                        random_state=1234)),\n",
       "             'Continental': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'Thales': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Thermo Fisher Scientific': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Google': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Nokia': (102,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=102,\n",
       "                                        random_state=1234)),\n",
       "             'Ericsson-Worldwide': (102,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=102,\n",
       "                                        random_state=1234)),\n",
       "             'Procter & Gamble': (82,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=82,\n",
       "                                        random_state=1234)),\n",
       "             'ABB': (42,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=42,\n",
       "                                        random_state=1234)),\n",
       "             'Hewlett Packard Enterprise | HPE': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Capgemini': (52,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=52,\n",
       "                                        random_state=1234)),\n",
       "             'VMware': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Dell Technologies': (157,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=157,\n",
       "                                        random_state=1234)),\n",
       "             'Salesforce': (52,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=52,\n",
       "                                        random_state=1234)),\n",
       "             'Johnson & Johnson': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Shell': (57,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=57,\n",
       "                                        random_state=1234)),\n",
       "             'IQVIA': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'PwC': (127,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=127,\n",
       "                                        random_state=1234)),\n",
       "             'Siemens': (97,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=97,\n",
       "                                        random_state=1234)),\n",
       "             'KPMG': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Vodafone': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'EY': (102,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=102,\n",
       "                                        random_state=1234)),\n",
       "             'Société Générale': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Amdocs': (52,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=52,\n",
       "                                        random_state=1234)),\n",
       "             'SAP': (87,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=87,\n",
       "                                        random_state=1234)),\n",
       "             'NCR': (57,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=57,\n",
       "                                        random_state=1234)),\n",
       "             'Luxoft': (32,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=32,\n",
       "                                        random_state=1234)),\n",
       "             'Roche': (37,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=37,\n",
       "                                        random_state=1234)),\n",
       "             'Verizon': (52,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=52,\n",
       "                                        random_state=1234)),\n",
       "             'Accenture': (112,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=112,\n",
       "                                        random_state=1234)),\n",
       "             'Cisco Systems': (107,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=107,\n",
       "                                        random_state=1234)),\n",
       "             'Schneider Electric': (77,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=77,\n",
       "                                        random_state=1234)),\n",
       "             'HP Inc.': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'Synopsys': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'Mondelēz International': (62,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=62,\n",
       "                                        random_state=1234)),\n",
       "             'Honeywell': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Marriott International': (67,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=67,\n",
       "                                        random_state=1234)),\n",
       "             'Nielsen': (72,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=72,\n",
       "                                        random_state=1234)),\n",
       "             'Intel Corporation': (77,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=77,\n",
       "                                        random_state=1234)),\n",
       "             'Uber': (37,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=37,\n",
       "                                        random_state=1234)),\n",
       "             'McKinsey & Company': (92,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=92,\n",
       "                                        random_state=1234)),\n",
       "             'Cognizant Technology Solutions': (42,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=42,\n",
       "                                        random_state=1234)),\n",
       "             'JLL': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234)),\n",
       "             'J.P. Morgan': (47,\n",
       "              LatentDirichletAllocation(evaluate_every=2, max_iter=200, n_components=47,\n",
       "                                        random_state=1234))})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_topics_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hays',\n",
       " <155x1290 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2417 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizers_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate matrix summarizing distribution of docs (reviews) over topics\n",
    "docs_of_probas = defaultdict(pd.DataFrame)\n",
    "\n",
    "for tup in vectorizers_list:\n",
    "    docs_of_probas[tup[0]] = pd.DataFrame(best_topics_model[tup[0]][1].transform(tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.859127</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.753472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.970997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.890432</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.890432  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  0.001984  0.001984  0.859127  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.975347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.753472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         56        57        58        59        60        61        62  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         63        64        65        66        67        68        69  \\\n",
       "0  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984  0.001984   \n",
       "1  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472  0.003472   \n",
       "3  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408  0.000408   \n",
       "4  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543  0.001543   \n",
       "\n",
       "         70        71  \n",
       "0  0.001984  0.001984  \n",
       "1  0.000347  0.000347  \n",
       "2  0.003472  0.003472  \n",
       "3  0.000408  0.970997  \n",
       "4  0.001543  0.001543  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_of_probas['Hays'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the measures of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 617 ms, total: 2min 22s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "comP_h_results = defaultdict(float)\n",
    "\n",
    "for company, proba_df in docs_of_probas.items():\n",
    "    comP_h_results[company] = comph(proba_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Hays': 0.59938204560807,\n",
       "             'Boston Consulting Group': 0.5850236786653754,\n",
       "             'Oracle': 0.6009032983444482,\n",
       "             'Philips': 0.5984505264414839,\n",
       "             'IBM': 0.5874039260169989,\n",
       "             'Amazon': 0.6069402771068312,\n",
       "             'Orange': 0.5992706973171229,\n",
       "             'DXC Technology': 0.598646183202596,\n",
       "             'Deloitte': 0.5924741579571319,\n",
       "             'Citi': 0.5875625671644225,\n",
       "             'Microsoft': 0.598481816057546,\n",
       "             'Altran Group': 0.6033602192174002,\n",
       "             'NTT': 0.591552064338981,\n",
       "             'Continental': 0.5891079382813795,\n",
       "             'Thales': 0.6115898394023912,\n",
       "             'Thermo Fisher Scientific': 0.5814171282318377,\n",
       "             'Google': 0.5820191871204352,\n",
       "             'Nokia': 0.5911527192422398,\n",
       "             'Ericsson-Worldwide': 0.5907156058395693,\n",
       "             'Procter & Gamble': 0.5918299813830346,\n",
       "             'ABB': 0.5876714099182295,\n",
       "             'Hewlett Packard Enterprise | HPE': 0.5708606152973069,\n",
       "             'Capgemini': 0.5889256683603251,\n",
       "             'VMware': 0.5835762999719958,\n",
       "             'Dell Technologies': 0.5979242188768561,\n",
       "             'Salesforce': 0.5825109199181211,\n",
       "             'Johnson & Johnson': 0.5752025868527627,\n",
       "             'Shell': 0.5939367526485224,\n",
       "             'IQVIA': 0.5971752666186277,\n",
       "             'PwC': 0.5867750393970139,\n",
       "             'Siemens': 0.5908496369761909,\n",
       "             'KPMG': 0.5867954561843219,\n",
       "             'Vodafone': 0.59149665767159,\n",
       "             'EY': 0.5780475272022455,\n",
       "             'Société Générale': 0.5815078544419886,\n",
       "             'Amdocs': 0.5789280960399792,\n",
       "             'SAP': 0.5856275960106576,\n",
       "             'NCR': 0.6016360946716903,\n",
       "             'Luxoft': 0.5716932519402942,\n",
       "             'Roche': 0.587835672527428,\n",
       "             'Verizon': 0.5932456240173006,\n",
       "             'Accenture': 0.5929443264039796,\n",
       "             'Cisco Systems': 0.598179746148135,\n",
       "             'Schneider Electric': 0.5998692364364936,\n",
       "             'HP Inc.': 0.572505780694487,\n",
       "             'Synopsys': 0.6022815049487249,\n",
       "             'Mondelēz International': 0.6031581065733421,\n",
       "             'Honeywell': 0.5802385076574309,\n",
       "             'Marriott International': 0.5559112322657226,\n",
       "             'Nielsen': 0.5959036724661755,\n",
       "             'Intel Corporation': 0.5972027317228161,\n",
       "             'Uber': 0.5822876791127185,\n",
       "             'McKinsey & Company': 0.5967197548841673,\n",
       "             'Cognizant Technology Solutions': 0.5592095520330235,\n",
       "             'JLL': 0.5807740696867509,\n",
       "             'J.P. Morgan': 0.5709359833838388})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comP_h_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 217 ms, sys: 5.57 ms, total: 222 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "comT_h_results = defaultdict(float)\n",
    "\n",
    "for company, proba_df in docs_of_probas.items():\n",
    "    comT_h_results[company] = conth(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Hays': 1.3564581467313805,\n",
       "             'Boston Consulting Group': 1.3773753978354506,\n",
       "             'Oracle': 1.3960180432589377,\n",
       "             'Philips': 1.3222144330859782,\n",
       "             'IBM': 1.3906218097859446,\n",
       "             'Amazon': 1.5290729922388016,\n",
       "             'Orange': 1.2842297789079136,\n",
       "             'DXC Technology': 1.3334018748516523,\n",
       "             'Deloitte': 1.4045421606294648,\n",
       "             'Citi': 1.4406680576615685,\n",
       "             'Microsoft': 1.3865926685905663,\n",
       "             'Altran Group': 1.3019209535252456,\n",
       "             'NTT': 1.269429126080505,\n",
       "             'Continental': 1.3440344548653722,\n",
       "             'Thales': 1.2376411761239516,\n",
       "             'Thermo Fisher Scientific': 1.348286884044163,\n",
       "             'Google': 1.3933435193800052,\n",
       "             'Nokia': 1.3720229430315414,\n",
       "             'Ericsson-Worldwide': 1.3595152088343005,\n",
       "             'Procter & Gamble': 1.3446942266382103,\n",
       "             'ABB': 1.296036059699818,\n",
       "             'Hewlett Packard Enterprise | HPE': 1.376515420553967,\n",
       "             'Capgemini': 1.330029364943503,\n",
       "             'VMware': 1.3396428414425476,\n",
       "             'Dell Technologies': 1.380064081855391,\n",
       "             'Salesforce': 1.3553605282896994,\n",
       "             'Johnson & Johnson': 1.3555496803266869,\n",
       "             'Shell': 1.2992943554879914,\n",
       "             'IQVIA': 1.3127875228658628,\n",
       "             'PwC': 1.5579516223075696,\n",
       "             'Siemens': 1.3940203900748982,\n",
       "             'KPMG': 1.3695322797614136,\n",
       "             'Vodafone': 1.3185622577579936,\n",
       "             'EY': 1.6490158843543123,\n",
       "             'Société Générale': 1.3847048837593943,\n",
       "             'Amdocs': 1.3639227009492882,\n",
       "             'SAP': 1.4092952307009514,\n",
       "             'NCR': 1.2820324288413312,\n",
       "             'Luxoft': 1.3353806348938335,\n",
       "             'Roche': 1.2813929294239998,\n",
       "             'Verizon': 1.300265312508633,\n",
       "             'Accenture': 1.412376932426072,\n",
       "             'Cisco Systems': 1.355506784928263,\n",
       "             'Schneider Electric': 1.3080441747876235,\n",
       "             'HP Inc.': 1.3660009406312614,\n",
       "             'Synopsys': 1.2897123839013875,\n",
       "             'Mondelēz International': 1.2664231300024085,\n",
       "             'Honeywell': 1.3827515118972762,\n",
       "             'Marriott International': 1.498893501843402,\n",
       "             'Nielsen': 1.3123397010286755,\n",
       "             'Intel Corporation': 1.3182940919166464,\n",
       "             'Uber': 1.302888178259638,\n",
       "             'McKinsey & Company': 1.3607118465497927,\n",
       "             'Cognizant Technology Solutions': 1.4083021789097785,\n",
       "             'JLL': 1.3367196717513965,\n",
       "             'J.P. Morgan': 1.376716976827474})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comT_h_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_avg(probMatrix):\n",
    "    entropy_list = []\n",
    "    for i in range(len(probMatrix)): \n",
    "        entropy_list.append(sp.stats.entropy(probMatrix[i]))\n",
    "    return np.mean(entropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 235 ms, sys: 6.31 ms, total: 242 ms\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "entropy_avg_results = defaultdict(float)\n",
    "\n",
    "for company, proba_df in docs_of_probas.items():\n",
    "    entropy_avg_results[company] = ent_avg(proba_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Hays': 0.9347030644082308,\n",
       "             'Boston Consulting Group': 0.940904311154074,\n",
       "             'Oracle': 1.0858373795464102,\n",
       "             'Philips': 0.9475818681114859,\n",
       "             'IBM': 1.070987978065448,\n",
       "             'Amazon': 1.2557512025405413,\n",
       "             'Orange': 0.8347193130021504,\n",
       "             'DXC Technology': 0.9096828829844992,\n",
       "             'Deloitte': 1.0500737999881138,\n",
       "             'Citi': 1.139216960597608,\n",
       "             'Microsoft': 1.0691058942009501,\n",
       "             'Altran Group': 0.8511341941971913,\n",
       "             'NTT': 0.7138935886016018,\n",
       "             'Continental': 0.9433195860921886,\n",
       "             'Thales': 0.7442552037795543,\n",
       "             'Thermo Fisher Scientific': 0.9359049204254245,\n",
       "             'Google': 1.0206889088327655,\n",
       "             'Nokia': 1.0592845262753936,\n",
       "             'Ericsson-Worldwide': 1.0574781404568672,\n",
       "             'Procter & Gamble': 0.9839316990623069,\n",
       "             'ABB': 0.804199290029007,\n",
       "             'Hewlett Packard Enterprise | HPE': 0.9789256229778555,\n",
       "             'Capgemini': 0.8846211938375014,\n",
       "             'VMware': 0.88981990550606,\n",
       "             'Dell Technologies': 1.1268439229528262,\n",
       "             'Salesforce': 0.9366118424454806,\n",
       "             'Johnson & Johnson': 0.9367435783692368,\n",
       "             'Shell': 0.8569642613599169,\n",
       "             'IQVIA': 0.8714831392976896,\n",
       "             'PwC': 1.2235498859835248,\n",
       "             'Siemens': 1.0655555871252989,\n",
       "             'KPMG': 0.8971862344565518,\n",
       "             'Vodafone': 0.9050689313678036,\n",
       "             'EY': 1.2738275758237465,\n",
       "             'Société Générale': 1.0461609743634463,\n",
       "             'Amdocs': 0.9466386783392696,\n",
       "             'SAP': 1.0867276973675815,\n",
       "             'NCR': 0.8159210900003002,\n",
       "             'Luxoft': 0.835894083598978,\n",
       "             'Roche': 0.7713140585988855,\n",
       "             'Verizon': 0.8414982443819401,\n",
       "             'Accenture': 1.093035194689267,\n",
       "             'Cisco Systems': 1.0286940998808987,\n",
       "             'Schneider Electric': 0.9055327099014271,\n",
       "             'HP Inc.': 0.9593250318091845,\n",
       "             'Synopsys': 0.8333417813177973,\n",
       "             'Mondelēz International': 0.7906701137772604,\n",
       "             'Honeywell': 1.0238877427674469,\n",
       "             'Marriott International': 1.2320891341040228,\n",
       "             'Nielsen': 0.9072877046275004,\n",
       "             'Intel Corporation': 0.925310896564716,\n",
       "             'Uber': 0.8029772260085175,\n",
       "             'McKinsey & Company': 0.9965329179604767,\n",
       "             'Cognizant Technology Solutions': 1.026314524785765,\n",
       "             'JLL': 0.8971931205917959,\n",
       "             'J.P. Morgan': 0.9739392056040841})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the cross-entropy of two probability distributions\n",
    "def cross_entropy(p, q):\n",
    "    for i in range(len(p)):\n",
    "        p[i] = p[i]+1e-12\n",
    "    for i in range(len(q)):\n",
    "        q[i] = q[i]+1e-12\n",
    "\n",
    "    return -sum([p[i] * np.log2(q[i]) for i in range(len(p))])\n",
    "\n",
    "# function to compute the average cross-entropy of a matrix\n",
    "def avg_crossEnt(probMatrix): \n",
    "#    NOTE: Cross entropy is not symmetric. \n",
    "#    This function takes both cross-entropy(p,q) and cross-entropy(q,p) \n",
    "#    into account when computing the avg\n",
    "    crossEntropy_list = []\n",
    "    for i in range(len(probMatrix)):\n",
    "        for j in range(len(probMatrix)): \n",
    "            if i != j:\n",
    "                crossEntropy_list.append(cross_entropy(probMatrix[i], probMatrix[j]))\n",
    "    return np.mean(crossEntropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 19s, sys: 1.36 s, total: 11min 21s\n",
      "Wall time: 11min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cross_entropy_results = defaultdict(float)\n",
    "\n",
    "for company, proba_df in docs_of_probas.items():\n",
    "    cross_entropy_results[company] = avg_crossEnt(proba_df.values)\n",
    "    \n",
    "# avg_crossEnt(docs_topics_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Hays': 9.45118768215931,\n",
       "             'Boston Consulting Group': 8.992603143668836,\n",
       "             'Oracle': 10.236883386216952,\n",
       "             'Philips': 9.581171680357297,\n",
       "             'IBM': 9.482374507187536,\n",
       "             'Amazon': 11.02774639866361,\n",
       "             'Orange': 9.159664224451324,\n",
       "             'DXC Technology': 9.314463527304103,\n",
       "             'Deloitte': 9.574724640288334,\n",
       "             'Citi': 9.711687249342075,\n",
       "             'Microsoft': 10.043317095352132,\n",
       "             'Altran Group': 9.36795758414793,\n",
       "             'NTT': 8.352029313034441,\n",
       "             'Continental': 8.988820556634364,\n",
       "             'Thales': 9.478352622134727,\n",
       "             'Thermo Fisher Scientific': 8.590687919835862,\n",
       "             'Google': 8.979765369278256,\n",
       "             'Nokia': 9.66275035995434,\n",
       "             'Ericsson-Worldwide': 9.654204974175151,\n",
       "             'Procter & Gamble': 9.39231563555692,\n",
       "             'ABB': 8.476985118333474,\n",
       "             'Hewlett Packard Enterprise | HPE': 8.380034508465569,\n",
       "             'Capgemini': 8.811671155482017,\n",
       "             'VMware': 8.5696653371366,\n",
       "             'Dell Technologies': 10.37101234543846,\n",
       "             'Salesforce': 8.723283991512856,\n",
       "             'Johnson & Johnson': 8.43354921559339,\n",
       "             'Shell': 8.98034884681369,\n",
       "             'IQVIA': 9.153767904007637,\n",
       "             'PwC': 9.910735058551607,\n",
       "             'Siemens': 9.592117273740962,\n",
       "             'KPMG': 8.608960133762132,\n",
       "             'Vodafone': 9.030351162347154,\n",
       "             'EY': 9.530188366323213,\n",
       "             'Société Générale': 9.034623563329125,\n",
       "             'Amdocs': 8.612658592210373,\n",
       "             'SAP': 9.384728428106195,\n",
       "             'NCR': 9.09907670383147,\n",
       "             'Luxoft': 7.948810903028108,\n",
       "             'Roche': 8.364942033105548,\n",
       "             'Verizon': 8.878976774389741,\n",
       "             'Accenture': 9.841517760996647,\n",
       "             'Cisco Systems': 9.869297406601783,\n",
       "             'Schneider Electric': 9.463268309278998,\n",
       "             'HP Inc.': 8.379601367515761,\n",
       "             'Synopsys': 9.260784482511742,\n",
       "             'Mondelēz International': 9.239588814613077,\n",
       "             'Honeywell': 8.952199526961373,\n",
       "             'Marriott International': 8.63027092479833,\n",
       "             'Nielsen': 9.273462552182131,\n",
       "             'Intel Corporation': 9.403816661012144,\n",
       "             'Uber': 8.29190785835761,\n",
       "             'McKinsey & Company': 9.637552745496185,\n",
       "             'Cognizant Technology Solutions': 8.132314287370235,\n",
       "             'JLL': 8.543366309368382,\n",
       "             'J.P. Morgan': 8.362394903483295})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
