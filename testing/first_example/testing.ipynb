{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "import scipy as sp\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_df = pd.read_pickle(\"Netflix_Data\")\n",
    "netflix_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>employerID</th>\n",
       "      <th>userID</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>highestEducation</th>\n",
       "      <th>metroID</th>\n",
       "      <th>metroName</th>\n",
       "      <th>stateID</th>\n",
       "      <th>stateName</th>\n",
       "      <th>countryID</th>\n",
       "      <th>jobTitleID</th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>GOC</th>\n",
       "      <th>GOCconfidence</th>\n",
       "      <th>MGOC</th>\n",
       "      <th>MGOCconfidence</th>\n",
       "      <th>reviewDateTime</th>\n",
       "      <th>isCurrentJobFlag</th>\n",
       "      <th>jobEndingYear</th>\n",
       "      <th>OverallRating</th>\n",
       "      <th>CareerOpps</th>\n",
       "      <th>CompensationBenefits</th>\n",
       "      <th>SeniorLeadership</th>\n",
       "      <th>Worklife</th>\n",
       "      <th>CultureValues</th>\n",
       "      <th>RecommendFriend</th>\n",
       "      <th>BusinessOutlook</th>\n",
       "      <th>CEO</th>\n",
       "      <th>employerName</th>\n",
       "      <th>stockTicker</th>\n",
       "      <th>employerTypeCode</th>\n",
       "      <th>numberEmployees</th>\n",
       "      <th>annualRevenue</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>4151950</td>\n",
       "      <td>11891</td>\n",
       "      <td>24353329</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>BACHELORS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 23:52:26.027</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>Same</td>\n",
       "      <td>Approve</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>COMPANY_PUBLIC</td>\n",
       "      <td>4700</td>\n",
       "      <td>8830669000</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>You will be working with the most talented ppl...</td>\n",
       "      <td>Little bit politics in some teams.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>1863</td>\n",
       "      <td>11891</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>2280</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>35739</td>\n",
       "      <td>Director, Product Management</td>\n",
       "      <td>product manager</td>\n",
       "      <td>0.913</td>\n",
       "      <td>product manager</td>\n",
       "      <td>0.913</td>\n",
       "      <td>2008-04-23 23:42:17.157</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approve</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>COMPANY_PUBLIC</td>\n",
       "      <td>4700</td>\n",
       "      <td>8830669000</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Freedom and responsibility. You're treated lik...</td>\n",
       "      <td>Netflix is not for everyone. You don't get \"di...</td>\n",
       "      <td>I have none. Senior management is fantastic. s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>4991</td>\n",
       "      <td>11891</td>\n",
       "      <td>2076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>2280</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>13321</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>1.000</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2008-06-11 00:03:28.907</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approve</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>COMPANY_PUBLIC</td>\n",
       "      <td>4700</td>\n",
       "      <td>8830669000</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Great colleagues -- incredible really</td>\n",
       "      <td>Domestic not global business -- wish we did eu...</td>\n",
       "      <td>Focus on the customer, not on Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14574</th>\n",
       "      <td>53799</td>\n",
       "      <td>11891</td>\n",
       "      <td>68043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>Portland</td>\n",
       "      <td>3163</td>\n",
       "      <td>OR</td>\n",
       "      <td>1</td>\n",
       "      <td>64668</td>\n",
       "      <td>Support Staff</td>\n",
       "      <td>support staff</td>\n",
       "      <td>1.000</td>\n",
       "      <td>retail representative</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2008-08-07 23:30:14.267</td>\n",
       "      <td>0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approve</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>COMPANY_PUBLIC</td>\n",
       "      <td>4700</td>\n",
       "      <td>8830669000</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>The upper management of Netflix really does se...</td>\n",
       "      <td>Specific to the Hillsboro location, the middle...</td>\n",
       "      <td>To the senior-most management in Los Gatos, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14584</th>\n",
       "      <td>53937</td>\n",
       "      <td>11891</td>\n",
       "      <td>68207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36451</td>\n",
       "      <td>Does IT Matter?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2008-08-08 09:12:42.493</td>\n",
       "      <td>0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approve</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>COMPANY_PUBLIC</td>\n",
       "      <td>4700</td>\n",
       "      <td>8830669000</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>The people there are fantastic, the service is...</td>\n",
       "      <td>It's frustrating to work for direct management...</td>\n",
       "      <td>Stop being so secretive, just be upfront and h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewID  employerID    userID  gender  birthYear highestEducation  \\\n",
       "5564    4151950       11891  24353329  FEMALE     1984.0        BACHELORS   \n",
       "5841       1863       11891        -1     NaN        NaN              NaN   \n",
       "6452       4991       11891      2076     NaN        NaN              NaN   \n",
       "14574     53799       11891     68043     NaN        NaN              NaN   \n",
       "14584     53937       11891     68207     NaN        NaN              NaN   \n",
       "\n",
       "       metroID metroName  stateID stateName  countryID  jobTitleID  \\\n",
       "5564         0       NaN        0       NaN          1           0   \n",
       "5841       761  San Jose     2280        CA          1       35739   \n",
       "6452       761  San Jose     2280        CA          1       13321   \n",
       "14574      700  Portland     3163        OR          1       64668   \n",
       "14584        0       NaN        0       NaN          1       36451   \n",
       "\n",
       "                           JobTitle                GOC  GOCconfidence  \\\n",
       "5564                            NaN                NaN            NaN   \n",
       "5841   Director, Product Management    product manager          0.913   \n",
       "6452              Marketing Manager  marketing manager          1.000   \n",
       "14574                 Support Staff      support staff          1.000   \n",
       "14584               Does IT Matter?                NaN          0.000   \n",
       "\n",
       "                        MGOC  MGOCconfidence           reviewDateTime  \\\n",
       "5564                     NaN             NaN  2014-04-30 23:52:26.027   \n",
       "5841         product manager           0.913  2008-04-23 23:42:17.157   \n",
       "6452       marketing manager           1.000  2008-06-11 00:03:28.907   \n",
       "14574  retail representative           1.000  2008-08-07 23:30:14.267   \n",
       "14584                    NaN           0.000  2008-08-08 09:12:42.493   \n",
       "\n",
       "       isCurrentJobFlag  jobEndingYear  OverallRating  CareerOpps  \\\n",
       "5564                  1            NaN            4.0         3.0   \n",
       "5841                  1            NaN            5.0         4.0   \n",
       "6452                  1            NaN            5.0         5.0   \n",
       "14574                 0         2008.0            2.0         1.0   \n",
       "14584                 0         2008.0            2.0         2.0   \n",
       "\n",
       "       CompensationBenefits  SeniorLeadership  Worklife  CultureValues  \\\n",
       "5564                    5.0               3.0       2.0            3.0   \n",
       "5841                    4.5               5.0       4.5            NaN   \n",
       "6452                    5.0               5.0       4.5            NaN   \n",
       "14574                   4.5               4.0       5.0            NaN   \n",
       "14584                   2.5               3.5       1.0            NaN   \n",
       "\n",
       "      RecommendFriend BusinessOutlook      CEO employerName stockTicker  \\\n",
       "5564              YES            Same  Approve      Netflix        NFLX   \n",
       "5841              YES             NaN  Approve      Netflix        NFLX   \n",
       "6452              YES             NaN  Approve      Netflix        NFLX   \n",
       "14574              NO             NaN  Approve      Netflix        NFLX   \n",
       "14584              NO             NaN  Approve      Netflix        NFLX   \n",
       "\n",
       "      employerTypeCode  numberEmployees  annualRevenue  industry  \\\n",
       "5564    COMPANY_PUBLIC             4700     8830669000  Internet   \n",
       "5841    COMPANY_PUBLIC             4700     8830669000  Internet   \n",
       "6452    COMPANY_PUBLIC             4700     8830669000  Internet   \n",
       "14574   COMPANY_PUBLIC             4700     8830669000  Internet   \n",
       "14584   COMPANY_PUBLIC             4700     8830669000  Internet   \n",
       "\n",
       "                       sector  \\\n",
       "5564   Information Technology   \n",
       "5841   Information Technology   \n",
       "6452   Information Technology   \n",
       "14574  Information Technology   \n",
       "14584  Information Technology   \n",
       "\n",
       "                                                    pros  \\\n",
       "5564   You will be working with the most talented ppl...   \n",
       "5841   Freedom and responsibility. You're treated lik...   \n",
       "6452               Great colleagues -- incredible really   \n",
       "14574  The upper management of Netflix really does se...   \n",
       "14584  The people there are fantastic, the service is...   \n",
       "\n",
       "                                                    cons  \\\n",
       "5564                  Little bit politics in some teams.   \n",
       "5841   Netflix is not for everyone. You don't get \"di...   \n",
       "6452   Domestic not global business -- wish we did eu...   \n",
       "14574  Specific to the Hillsboro location, the middle...   \n",
       "14584  It's frustrating to work for direct management...   \n",
       "\n",
       "                                                feedback  \n",
       "5564                                                 NaN  \n",
       "5841   I have none. Senior management is fantastic. s...  \n",
       "6452                 Focus on the customer, not on Apple  \n",
       "14574  To the senior-most management in Los Gatos, I ...  \n",
       "14584  Stop being so secretive, just be upfront and h...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = netflix_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You will be working with the most talented ppl around.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pros = netflix_df['pros'].tolist()\n",
    "data_pros[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = nltk.stem.PorterStemmer()\n",
    "class PStemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(PStemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([porter_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class SBStemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(SBStemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([snowball_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "class LemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([lemma.lemmatize(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_path(path):\n",
    "    import os\n",
    "    file_list=os.listdir(path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsd(p, q, base=np.e): # JS distance between probability vectors, used to compute compH\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    m = 1./2*(p + q)\n",
    "    return sp.stats.entropy(p, m, base=base) / 2. +  sp.stats.entropy(q, m, base=base) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conth(prob_matrix_df): # function to measure content heterogeneity given a topic (prob) matrix\n",
    "    N = prob_matrix_df.shape[0]\n",
    "    probMatrix = prob_matrix_df.values\n",
    "    conth = 1/((sum(map(sum, np.square(probMatrix))))/N)\n",
    "    return conth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comph(probMatrix_df): \n",
    "    #Transform probMatrix_df into 2D array\n",
    "    probMatrix = probMatrix_df\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(0, len(probMatrix)): \n",
    "        jsd_list = []\n",
    "        for y in range(0, len(probMatrix)): \n",
    "            jsd_list.append(jsd(probMatrix[x], probMatrix[y]))\n",
    "            y = y+1\n",
    "        df[str(x)] = jsd_list\n",
    "\n",
    "\n",
    "    #Get df lower diagonal\n",
    "    mask = np.ones(df.shape,dtype='bool')\n",
    "    mask[np.triu_indices(len(df))] = False\n",
    "    df_lower_diagonal = df[(df>-1)&mask]\n",
    "    \n",
    "    distance_list = []\n",
    "    k = 0 \n",
    "    for k in range(0, len(df)): \n",
    "    #Transform each column of df_lower_diagonal into list\n",
    "        column_list = df_lower_diagonal[str(k)].values.tolist()\n",
    "        #Drop nan values from column_list - to retain only actual values from lower diagonal \n",
    "        column_lower_diagonal_list = [l for l in column_list if (math.isnan(l) == False)]\n",
    "        for d in column_lower_diagonal_list: \n",
    "            distance_list.append(d)\n",
    "        k = k + 1\n",
    "    comph = sum(distance_list) / float(len(distance_list))\n",
    "    return comph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pros_clean(item):\n",
    "    if item != \"\":\n",
    "        item = item.lower().replace(\"netflix\", \" \")\n",
    "        item = item.replace(\"show less\", \"\")\n",
    "        item = item.replace(\"show more\", \"\")\n",
    "        item = item.replace(\"\\n\", \"\")\n",
    "        item_modified =  ''.join([i for i in item if not i.isdigit()])\n",
    "    return item_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cf.ProcessPoolExecutor() as executor:\n",
    "    data_pros_cleaned = executor.map(get_pros_clean, data_pros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pros_cleaned = list(data_pros_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalWords_vectorizer = SBStemmedCountVectorizer(analyzer=\"word\", stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalWords_tf = TotalWords_vectorizer.fit_transform(data_pros_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totWords = len(TotalWords_vectorizer.get_feature_names())\n",
    "totWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = SBStemmedCountVectorizer(max_df = 0.90, \n",
    "                                         min_df=0.01, \n",
    "                                         analyzer=\"word\", \n",
    "                                         stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf_vectorizer.fit_transform(data_pros_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abil',\n",
       " 'abl',\n",
       " 'account',\n",
       " 'actual',\n",
       " 'adult',\n",
       " 'allow',\n",
       " 'amaz',\n",
       " 'appreci',\n",
       " 'approv',\n",
       " 'area']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "tf_feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "percVoc = len(tf_feature_names)/float(totWords)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0    \n",
    "output=np.zeros((60,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<693x340 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for topics in range(2, 300, 5): \n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=topics, \n",
    "                                    max_iter=200, \n",
    "                                    learning_method='batch', \n",
    "                                    learning_offset=10.,\n",
    "                                    evaluate_every=2,\n",
    "                                    random_state=1234,\n",
    "                                    n_jobs=-1)\n",
    "    lda_fit = lda.fit(tf)\n",
    "    #output normalized matrix with distributions of topics over words\n",
    "    #normalized\n",
    "    topicsOverWords = lda_fit.components_ / lda_fit.components_.sum(axis=1)[:, np.newaxis]\n",
    "    topicsDissim_avg = comph(topicsOverWords)\n",
    "\n",
    "    #store results per firm   \n",
    "    output[i,0] = topics\n",
    "    output[i,1] = topicsDissim_avg \n",
    "    output[i,2] = percVoc\n",
    "  \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_save = (\"TopicInterpretation_Netflix_Pros_OptimalTopics_Coherence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open(filename_save + '.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = csv.writer(results)\n",
    "writer.writerow(['topics', 'coherence', 'voc%'])\n",
    "for values in output:\n",
    "    writer.writerow(values)\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_coherence_df = pd.read_csv(filename_save + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>voc%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topics  coherence  voc%\n",
       "0     0.0        0.0   0.0\n",
       "1     0.0        0.0   0.0\n",
       "2     0.0        0.0   0.0\n",
       "3     0.0        0.0   0.0\n",
       "4     0.0        0.0   0.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_coherence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_topics = topics_coherence_df.topics[topics_coherence_df.coherence.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = SBStemmedCountVectorizer(max_df = 0.90, \n",
    "                                         min_df=0.01, \n",
    "                                         analyzer=\"word\", \n",
    "                                         stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize data (learn the vocabulary dictionary and return term-document matrix)\n",
    "tf = tf_vectorizer.fit_transform(data_pros_cleaned)\n",
    "#tf = tf_vectorizer.fit_transform(data_cons_cleaned)\n",
    "#    extract features\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=int(optimal_topics),\n",
    "                                max_iter=200, \n",
    "                                learning_method='batch', \n",
    "                                learning_offset=10.,\n",
    "                                evaluate_every=2,\n",
    "                                random_state=1234,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for parameters of lda function - visit here: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "lda_fit = lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<693x340 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate matrix summarizing distribution of docs (reviews) over topics\n",
    "probMatrix = lda.transform(tf)\n",
    "docs_topics_df = pd.DataFrame(data = probMatrix, \n",
    "                              index=None, \n",
    "                              columns=None, \n",
    "                              dtype=None, \n",
    "                              copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.988592</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.367356</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.444765</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.182382</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.484240</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.323980</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.176313</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.138484</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.045797</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.988592  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.185923  0.000777  0.000777  0.000777   \n",
       "4  0.001166  0.001166  0.323980  0.001166  0.001166  0.001166  0.199497   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.124921  0.000777  0.000777  0.000777   \n",
       "4  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.367356  0.006061  0.006061  0.006061  0.006061  0.006061  0.444765   \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.000777  0.000777  0.182382   \n",
       "4  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166  0.176313   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0  0.010101  0.010101  0.676768  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.484240  0.000777  0.000777   \n",
       "4  0.001166  0.138484  0.001166  0.084460  0.001166  0.001166  0.001166   \n",
       "\n",
       "         28        29        30        31        32  \n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.000777  \n",
       "4  0.001166  0.001166  0.045797  0.001166  0.001166  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicModel(corpus, topics):\n",
    "    tf_vectorizer = SBStemmedCountVectorizer(max_df = 0.90, min_df=0.01, analyzer=\"word\", stop_words='english')\n",
    "    #vectorize data (learn the vocabulary dictionary and return term-document matrix)\n",
    "    tf = tf_vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    #for parameters of lda function - visit here: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "    lda = LatentDirichletAllocation(n_components=topics, \n",
    "                                max_iter=200, \n",
    "                                learning_method='batch', \n",
    "                                learning_offset=10.,\n",
    "                                evaluate_every=2,\n",
    "                                random_state=1234,\n",
    "                                n_jobs=-1)\n",
    "    #Fit lda model according to the given training data and parameters\n",
    "    lda_fit = lda.fit(tf)\n",
    "    \n",
    "    #Output: Distribution of topics per document (project data to maximize class separation)\n",
    "    probMatrix = lda.transform(tf)\n",
    "    #Transform superCorpus_theta into pandas df\n",
    "    probMatrix_df = pd.DataFrame(data = probMatrix, index=None, columns=None, dtype=None, copy=False)\n",
    "    \n",
    "    return probMatrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_over_topics = topicModel(data_pros_cleaned, int(optimal_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.988592</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.367356</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.444765</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.182382</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.484240</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.323980</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.176313</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.138484</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.045797</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.988592  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.185923  0.000777  0.000777  0.000777   \n",
       "4  0.001166  0.001166  0.323980  0.001166  0.001166  0.001166  0.199497   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.124921  0.000777  0.000777  0.000777   \n",
       "4  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.367356  0.006061  0.006061  0.006061  0.006061  0.006061  0.444765   \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.000777  0.000777  0.182382   \n",
       "4  0.001166  0.001166  0.001166  0.001166  0.001166  0.001166  0.176313   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0  0.010101  0.010101  0.676768  0.010101  0.010101  0.010101  0.010101   \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357  0.000357   \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061  0.006061   \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.484240  0.000777  0.000777   \n",
       "4  0.001166  0.138484  0.001166  0.084460  0.001166  0.001166  0.001166   \n",
       "\n",
       "         28        29        30        31        32  \n",
       "0  0.010101  0.010101  0.010101  0.010101  0.010101  \n",
       "1  0.000357  0.000357  0.000357  0.000357  0.000357  \n",
       "2  0.006061  0.006061  0.006061  0.006061  0.006061  \n",
       "3  0.000777  0.000777  0.000777  0.000777  0.000777  \n",
       "4  0.001166  0.001166  0.045797  0.001166  0.001166  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_over_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_H = comph(docs_over_topics)\n",
    "compH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.66 ms, sys: 824 µs, total: 6.48 ms\n",
      "Wall time: 5.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "conT_H = conth(docs_over_topics)\n",
    "conT_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
