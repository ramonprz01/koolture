{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from joblib import parallel_backend\n",
    "from dask.distributed import Client\n",
    "import joblib\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "import math, re\n",
    "import numpy as np\n",
    "import csv\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# from numba import jit\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_df = pd.read_csv(\"netflix.csv\")\n",
    "netflix_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def tokenize_snow(text):\n",
    "    stem = nltk.stem.SnowballStemmer('english')\n",
    "    text = text.lower()\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation: continue\n",
    "        yield stem.stem(token)\n",
    "        \n",
    "def tokenize_lemma(text):\n",
    "    stem = nltk.wordnet.WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation: continue\n",
    "        yield stem.stem(token)\n",
    "        \n",
    "def tokenize_stem(text):\n",
    "    stem = nltk.stem.PorterStemmer()\n",
    "    text = text.lower()\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation: continue\n",
    "        yield stem.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython=True)\n",
    "def jsd(p, q, base=np.e): # JS distance between probability vectors, used to compute compH\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    m = 1 / 2 * (p + q)\n",
    "    \n",
    "    return sp.stats.entropy(p, m, base=base) / 2 +  sp.stats.entropy(q, m, base=base) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython=True)\n",
    "def conth(p_mtx_df): # function to measure content heterogeneity given a topic (prob) matrix\n",
    "    '''\n",
    "    How is this review spread across the topics.\n",
    "    Then you take the average values across the reviews\n",
    "    Herfindall index\n",
    "    Assuming the reviews are about culture\n",
    "    Are people on average focus on a few cultural values (topics) when they write their review\n",
    "    '''\n",
    "    return (1 / ((sum(map(sum, np.square(p_mtx_df.values)))) / p_mtx_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs to have an additional argument. Or be completely redisigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comph(probMatrix_df, arr_or_df='df'): \n",
    "\n",
    "    if arr_or_df == 'df':\n",
    "        probMatrix = probMatrix_df\n",
    "    else:\n",
    "        probMatrix = probMatrix_df.values\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(len(probMatrix)): \n",
    "        jsd_list = []\n",
    "        for y in range(len(probMatrix)): \n",
    "            jsd_list.append(jsd(probMatrix[x], probMatrix[y]))\n",
    "        df[str(x)] = jsd_list\n",
    "\n",
    "    #Get df lower diagonal\n",
    "    mask = np.ones(df.shape, dtype='bool')\n",
    "    mask[np.triu_indices(len(df))] = False\n",
    "    df_lower_diagonal = df[(df>-1) & mask]\n",
    "    \n",
    "    distance_list = []\n",
    "    for k in df.columns: \n",
    "    #Transform each column of df_lower_diagonal into list\n",
    "        col_array = df_lower_diagonal.loc[df_lower_diagonal[k].notna(), k].values\n",
    "        for d in col_array:\n",
    "            distance_list.append(d)\n",
    "\n",
    "    return (sum(distance_list) / len(distance_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_name_out(data, col_to_search, col_reviews, companies_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in a dataframe, the name of the column with all of \n",
    "    the companies, the name of the column with the reviews, and an iterable\n",
    "    with the companies names that are in the dataset. The latter could be a list,\n",
    "    set, Series, tuple, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    for company in companies_list:\n",
    "        condition = (data[col_to_search] == company)\n",
    "        data.loc[condition, col_reviews] = data.loc[condition, col_reviews].str.lower().str.strip(company.lower())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_list = ['Netflix', 'amazon'] \n",
    "netflix_df = comp_name_out(netflix_df, 'employerName', 'pros', comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you will be working with the most talented ppl around.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pros = netflix_df['pros'].values\n",
    "data_pros[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_doc(doc):\n",
    "    \"\"\"\n",
    "    This function normalizes your list of documents by taking only\n",
    "    words, numbers, and spaces in between them. It then filters out\n",
    "    stop words if you want to.\n",
    "    \"\"\"\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    filtered_tokens = [token for token in tokens]\n",
    "#     filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "corp_normalizer = np.vectorize(normalize_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.52046783625731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cf.ProcessPoolExecutor() as executor:\n",
    "    data_pros_cleaned = executor.map(normalize_doc, data_pros)\n",
    "    data_pros_cleaned = list(data_pros_cleaned)\n",
    "\n",
    "TotalWords_vectorizer = CountVectorizer(stop_words='english')\n",
    "TotalWords_tf = TotalWords_vectorizer.fit_transform(data_pros_cleaned)\n",
    "totWords = len(TotalWords_vectorizer.get_feature_names())\n",
    "# totWords\n",
    "\n",
    "\n",
    "tf_vectorizer = CountVectorizer(tokenizer=tokenize_snow, max_df = 0.90, min_df=0.01)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(data_pros_cleaned)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "percVoc = len(tf_feature_names) / totWords * 100\n",
    "percVoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with topic 2\n",
      "Done with topic 7\n",
      "Done with topic 12\n",
      "Done with topic 17\n",
      "Done with topic 22\n",
      "Done with topic 27\n",
      "Done with topic 32\n",
      "Done with topic 37\n",
      "Done with topic 42\n",
      "Done with topic 47\n",
      "Done with topic 52\n",
      "Done with topic 57\n",
      "Done with topic 62\n",
      "Done with topic 67\n",
      "Done with topic 72\n",
      "Done with topic 77\n",
      "Done with topic 82\n",
      "Done with topic 87\n",
      "Done with topic 92\n",
      "Done with topic 97\n",
      "Done with topic 102\n",
      "Done with topic 107\n",
      "Done with topic 112\n",
      "Done with topic 117\n",
      "Done with topic 122\n",
      "Done with topic 127\n",
      "Done with topic 132\n",
      "Done with topic 137\n",
      "Done with topic 142\n",
      "Done with topic 147\n",
      "Done with topic 152\n",
      "Done with topic 157\n",
      "Done with topic 162\n",
      "Done with topic 167\n",
      "Done with topic 172\n",
      "Done with topic 177\n",
      "Done with topic 182\n",
      "Done with topic 187\n",
      "Done with topic 192\n",
      "Done with topic 197\n",
      "Done with topic 202\n",
      "Done with topic 207\n",
      "Done with topic 212\n",
      "Done with topic 217\n",
      "Done with topic 222\n",
      "Done with topic 227\n",
      "Done with topic 232\n",
      "Done with topic 237\n",
      "Done with topic 242\n",
      "Done with topic 247\n",
      "Done with topic 252\n",
      "Done with topic 257\n",
      "Done with topic 262\n",
      "Done with topic 267\n",
      "Done with topic 272\n",
      "Done with topic 277\n",
      "Done with topic 282\n",
      "Done with topic 287\n",
      "Done with topic 292\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "i = 0    \n",
    "output=np.zeros((60,3))\n",
    "\n",
    "#totWordsPerdocument = np.sum(tf_matrix, axis=1)\n",
    "for topics in range(2,300,5): \n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=topics, max_iter=200, \n",
    "                                    learning_method='online',random_state=1234, n_jobs=-1)\n",
    "    lda_fit = lda.fit(tf)\n",
    "    #output normalized matrix with distributions of topics over words\n",
    "    #normalized\n",
    "    topicsOverWords = lda_fit.components_ / lda_fit.components_.sum(axis=1)[:, np.newaxis]\n",
    "    topicsDissim_avg = comph(topicsOverWords)\n",
    "\n",
    "#store results per firm   \n",
    "    output[i,0] = topics\n",
    "    output[i,1] = topicsDissim_avg \n",
    "    output[i,2] = percVoc\n",
    "  \n",
    "    i = i+1\n",
    "    \n",
    "    print(f'Done with topic {topics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "output = defaultdict(np.float32)\n",
    "\n",
    "for i, topics in enumerate(range(2, 300, 5)):\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=topics, max_iter=200, learning_method='online', \n",
    "                                    random_state=1234, n_jobs=-1)\n",
    "    ldamo = lda.fit(tf)\n",
    "\n",
    "    #output normalized matrix with distributions of topics over words\n",
    "    #normalized\n",
    "    topicsOverWords = ldamo.components_ / ldamo.components_.sum(axis=1)[:, np.newaxis]\n",
    "    topicsDissim_avg = comph(topicsOverWords)\n",
    "\n",
    "    #store results per firm   \n",
    "    output[i] = (topics, topicsDissim_avg, percVoc)\n",
    "    print(f'Done with topic {topics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# to use joblib with dask we need a client\n",
    "# client = Client(processes=False)\n",
    "mo_list = []\n",
    "\n",
    "\n",
    "for topics in range(2, 300, 5):\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        lda = LatentDirichletAllocation(n_components=topics, max_iter=200, learning_method='batch', \n",
    "                                        learning_offset=10., evaluate_every=2, random_state=1234)#, n_jobs=-1)\n",
    "        ldamo = lda.fit(tf)\n",
    "        mo_list.append((topics, ldamo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = (ldamo.components_ / ldamo.components_.sum(axis=1)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_coherence_df = pd.DataFrame(output, columns=['topics', 'coherence', 'voc%'])\n",
    "topics_coherence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_topics = int(topics_coherence_df.loc[topics_coherence_df['coherence'].idxmax(), 'topics'])\n",
    "optimal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=optimal_topics,\n",
    "                                max_iter=200, \n",
    "                                learning_method='batch', \n",
    "                                learning_offset=10.,\n",
    "                                evaluate_every=2,\n",
    "                                random_state=1234,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate matrix summarizing distribution of docs (reviews) over topics\n",
    "probMatrix = lda.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.57894737e-04, 6.57894737e-04, 6.57894737e-04, ...,\n",
       "        6.57894737e-04, 6.57894737e-04, 6.57894737e-04],\n",
       "       [2.61069340e-05, 2.61069340e-05, 2.61069340e-05, ...,\n",
       "        2.61069340e-05, 2.61069340e-05, 2.61069340e-05],\n",
       "       [1.31578947e-03, 1.31578947e-03, 1.31578947e-03, ...,\n",
       "        1.31578947e-03, 1.31578947e-03, 1.31578947e-03],\n",
       "       ...,\n",
       "       [1.64473684e-03, 1.64473684e-03, 1.64473684e-03, ...,\n",
       "        1.64473684e-03, 1.64473684e-03, 1.64473684e-03],\n",
       "       [3.65497076e-04, 3.65497076e-04, 3.65497076e-04, ...,\n",
       "        3.65497076e-04, 3.65497076e-04, 3.65497076e-04],\n",
       "       [7.30994152e-04, 7.30994152e-04, 7.30994152e-04, ...,\n",
       "        7.30994152e-04, 7.30994152e-04, 7.30994152e-04]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.544156</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.257160</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.100658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.352092</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.201316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.201316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.201316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.201316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.991286</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.090855</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.246462</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.033049</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.056475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.090210</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.037210</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.043015</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.117588</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.090855  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        7         8         9         10        11        12        13   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.039472  0.000100   \n",
       "\n",
       "        14        15        16        17        18        19        20   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        21        22        23        24        25        26        27   \\\n",
       "0  0.000658  0.544156  0.000658  0.000658  0.000658  0.000658  0.257160   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        28        29        30        31        32        33        34   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.201316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.246462  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        35        36        37        38        39        40        41   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.201316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        42        43        44        45        46        47        48   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.991286   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        49        50        51        52        53        54        55   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.033049  0.000100  0.056475  0.000100  0.090210   \n",
       "\n",
       "        56        57        58        59        60        61        62   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.627100  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        63        64        65        66        67        68        69   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.100658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        70        71        72        73        74        75        76   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.038002  0.000100  0.000100  0.000100  0.019067  0.000100   \n",
       "\n",
       "        77        78        79        80        81        82        83   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.016918  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        84        85        86        87        88        89        90   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.037210  0.000100  0.023348  0.000100   \n",
       "\n",
       "        91        92        93        94        95        96        97   \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.033080  0.000100   \n",
       "\n",
       "        98        99        100       101       102       103       104  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.201316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        105       106       107       108       109       110       111  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        112       113       114       115       116       117       118  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.118411  0.000100   \n",
       "\n",
       "        119       120       121       122       123       124       125  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        126       127       128       129       130       131       132  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.043015  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        133       134       135       136       137       138       139  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.352092  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.117588  0.000100  0.000100   \n",
       "\n",
       "        140       141       142       143       144       145       146  \\\n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658  0.000658   \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026  0.000026   \n",
       "2  0.201316  0.001316  0.001316  0.001316  0.001316  0.001316  0.001316   \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058  0.000058   \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100  0.000100   \n",
       "\n",
       "        147       148       149       150       151  \n",
       "0  0.000658  0.000658  0.000658  0.000658  0.000658  \n",
       "1  0.000026  0.000026  0.000026  0.000026  0.000026  \n",
       "2  0.001316  0.001316  0.001316  0.001316  0.001316  \n",
       "3  0.000058  0.000058  0.000058  0.000058  0.000058  \n",
       "4  0.000100  0.000100  0.000100  0.000100  0.000100  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_topics_df = pd.DataFrame(data = probMatrix)\n",
    "docs_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 55.4 ms, total: 23 s\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6226699724544705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "comp_H = comph(docs_topics_df, arr_or_df='arr')\n",
    "comp_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 ms, sys: 244 s, total: 17.8 ms\n",
      "Wall time: 17.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1974641852117056"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "conT_H = conth(docs_topics_df)\n",
    "conT_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_avg(probMatrix): \n",
    "    import statistics\n",
    "    entropy_list = []\n",
    "    for i in range(len(probMatrix)): \n",
    "        entropy_list.append(entropy(probMatrix[i]))\n",
    "    entropy_avg = statistics.mean(entropy_list)\n",
    "    return entropy_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the cross-entropy of two probability distributions\n",
    "def cross_entropy(p, q):\n",
    "    for i in range(len(p)):\n",
    "        p[i] = p[i]+1e-12\n",
    "    for i in range(len(q)):\n",
    "        q[i] = q[i]+1e-12\n",
    "\n",
    "    return -sum([p[i]*log2(q[i]) for i in range(len(p))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the average cross-entropy of a matrix\n",
    "def avg_crossEnt(probMatrix): \n",
    "#    NOTE: Cross entropy is not symmetric. \n",
    "#    This function takes both cross-entropy(p,q) and cross-entropy(q,p) \n",
    "#    into account when computing the avg\n",
    "    crossEntropy_list = []\n",
    "    for i in range(len(probMatrix)):\n",
    "        for j in range(len(probMatrix)): \n",
    "            if i != j:\n",
    "                crossEntropy_list.append(cross_entropy(probMatrix[i], probMatrix[j]))\n",
    "    crossEntropy_avg = statistics.mean(crossEntropy_list)\n",
    "    return crossEntropy_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
