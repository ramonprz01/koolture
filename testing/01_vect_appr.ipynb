{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk, re\n",
    "# nltk.download('wordnet')\n",
    "import scipy as sp\n",
    "import math\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import csv\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_pickle(\"Netflix_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will remove the company names from their respective reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def comp_name_out(data, col_to_search, col_reviews, companies_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in a dataframe, the name of the column with all of \n",
    "    the companies, the name of the column with the reviews, and an iterable\n",
    "    with the companies names that are in the dataset. The latter could be a list,\n",
    "    set, Series, tuple, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    for company in companies_list:\n",
    "        condition = (data[col_to_search] == company)\n",
    "        data.loc[condition, col_reviews] = data.loc[condition, col_reviews].str.lower().str.strip(company.lower())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function helps with the preprocessing of the data. It runs after the lemmatizer, stemmer, snowball, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_doc(doc):\n",
    "    \"\"\"\n",
    "    This function normalizes your list of documents by taking only\n",
    "    words, numbers, and spaces in between them. It then filters out\n",
    "    stop words if you want to.\n",
    "    \"\"\"\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "#     filtered_tokens = [token for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "corp_normalizer = np.vectorize(normalize_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the root of the word. You can get all three (lemma, stem, and snow) or use them separately with the partial functions below. The function above and the function below have been vectorized, meaning, it is like a loop where you only need to pass your iterable to it and it applies the function to every single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_of_word(docs, root_word_method='lemma'):\n",
    "    porter_stemmer = nltk.stem.PorterStemmer()\n",
    "    snowball_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    \n",
    "    tokens = nltk.word_tokenize(docs)\n",
    "    \n",
    "    if root_word_method == 'lemma':\n",
    "        doc = ' '.join([lemma.lemmatize(w) for w in tokens])\n",
    "    elif root_word_method == 'stemm':\n",
    "        doc = ' '.join([porter_stemmer.stem(w) for w in tokens])\n",
    "    elif root_word_method == 'snowball':\n",
    "        doc = ' '.join([snowball_stemmer.stem(w) for w in tokens])\n",
    "        \n",
    "    return doc\n",
    "\n",
    "stemming = np.vectorize(partial(root_of_word, root_word_method='stemm'))\n",
    "snowball = np.vectorize(partial(root_of_word, root_word_method='snowball'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsd(p, q, base=np.e): # JS distance between probability vectors, used to compute compH\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    m = (1 / 2 * (p + q))\n",
    "    return sp.stats.entropy(p, m, base) / 2 +  sp.stats.entropy(q, m, base) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conth(data): # function to measure content heterogeneity given a topic (prob) matrix\n",
    "    return (1 / ((sum(map(sum, np.square(data.values)))) / data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comph(data): \n",
    "    #Transform probMatrix_df into 2D array\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(len(data)): \n",
    "        jsd_list = []\n",
    "        for y in range(len(data)): \n",
    "            jsd_list.append(jsd(data[x], data[y]))\n",
    "        df[str(x)] = jsd_list\n",
    "\n",
    "    #Get df lower diagonal\n",
    "    mask = np.ones(df.shape, dtype='bool')\n",
    "    mask[np.triu_indices(len(df))] = False\n",
    "    df_lower_diagonal = df[(df>-1) & mask]\n",
    "    \n",
    "    distance_list = []\n",
    "    for k in range(len(df)): \n",
    "    #Transform each column of df_lower_diagonal into list\n",
    "        column_list = df_lower_diagonal[str(k)].values.tolist()\n",
    "        #Drop nan values from column_list - to retain only actual values from lower diagonal \n",
    "        column_lower_diagonal_list = [l for l in column_list if (math.isnan(l) == False)]\n",
    "        for d in column_lower_diagonal_list: \n",
    "            distance_list.append(d)\n",
    "            \n",
    "    return sum(distance_list) / float(len(distance_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the company names from the reviews, and extract the reviews into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = ['Netflix', 'amazon'] \n",
    "netflix_df = comp_name_out(netflix_df, 'employerName', 'pros', comp_list)\n",
    "data_pros = netflix_df['pros'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the preprocessing functions in combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 749 ms, sys: 6.51 ms, total: 756 ms\n",
      "Wall time: 761 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['work talent ppl around',\n",
       "       'reedom respons treat like adult part pro team highli function compani well respect ha super posit brand awar never abl go anywher without get pepper rave happi custom comment love wear compani logo gear thi reason matter netflix dead wood everyon someth veri import compani would nt matter make differ feel good realli make differ matter role compani often repeat employe olymp team mean nt thi 247 life focu gold varsiti team play win veri good still balanc class learn need good worklif balanc veri import compani think best thing subtl thi vacationno holiday stuff work work seem realiz everyon work hard time night weekend often ton hard work want take time vacat long holiday day whatever happen discret nt ask nt get permiss one keep track never heard thi kind polici imagin doest moral feel like treat like grown rule alon think stand beyond ani org',\n",
       "       'great colleagu incred realli'], dtype='<U1247')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_pros_cleaned = corp_normalizer(stemming(data_pros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total words in the dictionary of review words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2130"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TotalWords_vectorizer = CountVectorizer()\n",
    "TotalWords_tf = TotalWords_vectorizer.fit_transform(data_pros)\n",
    "totWords = len(TotalWords_vectorizer.get_feature_names())\n",
    "totWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cleaned dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df = 0.90, min_df=0.01)\n",
    "tf = tf_vectorizer.fit_transform(data_pros_cleaned)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of words in the final dictionary that can be found in the full corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.981220657276996"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percVoc = len(tf_feature_names) / totWords * 100\n",
    "percVoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tuple that will collect the topic number, the dissimilarity average, and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Collect = namedtuple(\"Models\", \"topics diss_avg models\")\n",
    "output = Collect([], [], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model runs in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with topic 2\n",
      "Done with topic 7\n",
      "Done with topic 12\n",
      "Done with topic 17\n",
      "Done with topic 22\n",
      "Done with topic 27\n",
      "Done with topic 32\n",
      "Done with topic 37\n",
      "Done with topic 42\n",
      "Done with topic 47\n",
      "Done with topic 52\n",
      "Done with topic 57\n",
      "Done with topic 62\n",
      "Done with topic 67\n",
      "Done with topic 72\n",
      "Done with topic 77\n",
      "Done with topic 82\n",
      "Done with topic 87\n",
      "Done with topic 92\n",
      "Done with topic 97\n",
      "Done with topic 102\n",
      "Done with topic 107\n",
      "Done with topic 112\n",
      "Done with topic 117\n",
      "Done with topic 122\n",
      "Done with topic 127\n",
      "Done with topic 132\n",
      "Done with topic 137\n",
      "Done with topic 142\n",
      "Done with topic 147\n",
      "Done with topic 152\n",
      "Done with topic 157\n",
      "Done with topic 162\n",
      "Done with topic 167\n",
      "Done with topic 172\n",
      "Done with topic 177\n",
      "Done with topic 182\n",
      "Done with topic 187\n",
      "Done with topic 192\n",
      "Done with topic 197\n",
      "Done with topic 202\n",
      "Done with topic 207\n",
      "Done with topic 212\n",
      "Done with topic 217\n",
      "Done with topic 222\n",
      "Done with topic 227\n",
      "Done with topic 232\n",
      "Done with topic 237\n",
      "Done with topic 242\n",
      "Done with topic 247\n",
      "Done with topic 252\n",
      "Done with topic 257\n",
      "Done with topic 262\n",
      "Done with topic 267\n",
      "Done with topic 272\n",
      "Done with topic 277\n",
      "Done with topic 282\n",
      "Done with topic 287\n",
      "Done with topic 292\n",
      "Done with topic 297\n",
      "CPU times: user 4min 31s, sys: 35.9 s, total: 5min 7s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for topics in range(2, 300, 5): \n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=topics, max_iter=200, \n",
    "                                    learning_method='batch', learning_offset=10.,\n",
    "                                    evaluate_every=2, random_state=1234, n_jobs=-1)\n",
    "    \n",
    "    lda_model = lda.fit(tf)\n",
    "    topicsOverWords = lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    output.topics.append(topics)\n",
    "    output.diss_avg.append(comph(topicsOverWords))\n",
    "    output.models.append(lda_model)\n",
    "    \n",
    "    print(f\"Done with topic {topics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final dataframe with all three outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.309527</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.358032</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.423534</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0.424758</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.457503</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topics  coherence                                             models\n",
       "0       2   0.309527  LatentDirichletAllocation(evaluate_every=2, ma...\n",
       "1       7   0.358032  LatentDirichletAllocation(evaluate_every=2, ma...\n",
       "2      12   0.423534  LatentDirichletAllocation(evaluate_every=2, ma...\n",
       "3      17   0.424758  LatentDirichletAllocation(evaluate_every=2, ma...\n",
       "4      22   0.457503  LatentDirichletAllocation(evaluate_every=2, ma..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = pd.DataFrame(zip(*output), columns=['topics', 'coherence', 'models'])\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_topics = int(out_df.loc[out_df['coherence'].idxmax(), 'topics'])\n",
    "optimal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>162</td>\n",
       "      <td>0.552373</td>\n",
       "      <td>LatentDirichletAllocation(evaluate_every=2, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topics  coherence                                             models\n",
       "32     162   0.552373  LatentDirichletAllocation(evaluate_every=2, ma..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df[out_df['topics'] == optimal_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to run the model again since we already saved all of them in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = out_df.loc[out_df['topics'] == optimal_topics, 'models'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the corpus to get the probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate matrix summarizing distribution of docs (reviews) over topics\n",
    "docs_topics_df = pd.DataFrame(best_model.transform(tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the measures of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 138 ms, total: 25.6 s\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6001764879390206"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "comP_H = comph(docs_topics_df.values)\n",
    "comP_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 ms, sys: 1.37 ms, total: 21.8 ms\n",
      "Wall time: 22.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.068080930909674"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "conT_H = conth(docs_topics_df)\n",
    "conT_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_avg(probMatrix):\n",
    "    entropy_list = []\n",
    "    for i in range(len(probMatrix)): \n",
    "        entropy_list.append(sp.stats.entropy(probMatrix[i]))\n",
    "    entropy_avg = np.mean(entropy_list)\n",
    "    return entropy_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5340804507420907"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_avg(docs_topics_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the cross-entropy of two probability distributions\n",
    "def cross_entropy(p, q):\n",
    "    for i in range(len(p)):\n",
    "        p[i] = p[i]+1e-12\n",
    "    for i in range(len(q)):\n",
    "        q[i] = q[i]+1e-12\n",
    "\n",
    "    return -sum([p[i] * np.log2(q[i]) for i in range(len(p))])\n",
    "\n",
    "# function to compute the average cross-entropy of a matrix\n",
    "def avg_crossEnt(probMatrix): \n",
    "#    NOTE: Cross entropy is not symmetric. \n",
    "#    This function takes both cross-entropy(p,q) and cross-entropy(q,p) \n",
    "#    into account when computing the avg\n",
    "    crossEntropy_list = []\n",
    "    for i in range(len(probMatrix)):\n",
    "        for j in range(len(probMatrix)): \n",
    "            if i != j:\n",
    "                crossEntropy_list.append(cross_entropy(probMatrix[i], probMatrix[j]))\n",
    "    return np.mean(crossEntropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.590204388743519"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_crossEnt(docs_topics_df.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
